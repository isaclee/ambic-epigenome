#!/bin/bash -l

#SBATCH
#SBATCH --job-name=untar
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --mail-type=end
#SBATCH --mail-user=ilee29@jhmi.edu
#SBATCH --time=1:0:0

while :
do
  case "$1" in
    -i | --infile) #path to input tar
      infile=$2
      shift 2
      ;;
    -n | --numreads) # number of reads to extract
      n=$2
      shift 2
      ;;
    -o | --outdir) # directory of output
      outdir=$2
      shift 2
      ;;
    *) break
      ;;
  esac
done

# Load parallel
module load parallel

# check dir
if [ -e $outdir ]; then
  num=`find $outdir -name "*fast5*" | wc -l`
  if [ "$size" -ge "$n" ];then
    echo "$outdir already exists."
    exit
  fi
else
  mkdir $outdir
fi

cd $outdir
echo "output dir $PWD"

# execute code
echo "untarring from: $infile"
echo "$n files"
# to keep argument list short, I'll extract based on folders
folders=`tar -tf $infile | grep "fast5" | head -n $n | \
  awk 'BEGIN{ FS="/" }{ print $1 }' | uniq`
echo "extracting following folders : "$folders""
parallel tar xvzf $infile --occurrence {} ::: $folders
echo "Finished with job $SLURM_JOBID"
